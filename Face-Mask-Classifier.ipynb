{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64216c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import imutils \n",
    "from imutils import paths \n",
    "import sklearn \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b804e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096216cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Dataset3'\n",
    "imagePaths = list(paths.list_images(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0165f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all the images and assign them to the labels \n",
    "data=[]\n",
    "labels = []\n",
    "\n",
    "for i in imagePaths:\n",
    "    #Extract the labels from the file names\n",
    "    label = i.split(os.path.sep)[-2]  \n",
    "    #Load the input images and preprocess it \n",
    "    image = load_img(i,target_size=(224,224))\n",
    "    image = img_to_array(image)\n",
    "    image = preprocess_input(image)\n",
    "    #Update the data and label lists\n",
    "    data.append(image)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a763ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the data and labels to numpy array \n",
    "data = np.array(data, dtype= \"float32\")\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the labels \n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcefb931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partition the data into train and test \n",
    "(trainX,testX,trainY,testY) = train_test_split(data,labels, test_size = 0.20,stratify=labels,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca47ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the data \n",
    "print('Number of images in the training set   : ', len(trainX))\n",
    "print('Number of images in the validation set : ', len(testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct the training image generator for data augmentation \n",
    "aug = ImageDataGenerator(\n",
    "                         rotation_range = 40,\n",
    "                         zoom_range = 0.25,\n",
    "                         width_shift_range = 0.2,\n",
    "                         height_shift_range = 0.2,\n",
    "                         shear_range = 0.2,\n",
    "                         horizontal_flip = True,\n",
    "                         fill_mode ='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098cb88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the pre trained model \n",
    "baseModel = MobileNetV2(weights='imagenet', include_top = False, input_shape =(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructing the head of the model that will be placed on the top of the base model \n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size = (7,7))(headModel)\n",
    "headModel = Flatten(name = 'flatten')(headModel)\n",
    "headModel = Dense(128, activation = 'relu')(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation = 'softmax')(headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2320e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place the headModel on the top of the baseModel \n",
    "model = Model(inputs= baseModel.input, outputs = headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8dae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze the layers of base model so they will not be update \n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dec19e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 0.0001\n",
    "EPOCHS= 30\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print('The batch_size of the images : ', BATCH_SIZE)\n",
    "print('The epoch value for the training the model : ', EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b125b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the Model\n",
    "opt = Adam(learning_rate = INIT_LR, decay = INIT_LR/EPOCHS)\n",
    "model.compile(loss='binary_crossentropy', optimizer = opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeffafac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the Model\n",
    "H = model.fit(\n",
    "              aug.flow(trainX, trainY, batch_size = BATCH_SIZE),\n",
    "              steps_per_epoch = len(trainX)//BATCH_SIZE,\n",
    "              validation_data = (testX,testY),\n",
    "              validation_steps = len(testX)//BATCH_SIZE,\n",
    "              epochs = EPOCHS,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8994e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the training results \n",
    "acc = H.history['accuracy']\n",
    "val_acc = H.history['val_accuracy']\n",
    "\n",
    "loss = H.history['loss']\n",
    "val_loss = H.history['val_loss']\n",
    "\n",
    "epochs_range = range(30)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs_range,acc,label='Training Accuracy')\n",
    "plt.plot(epochs_range,val_acc,label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and validation Accuracy')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs_range,loss, label='Training Loss')\n",
    "plt.plot(epochs_range,val_loss,label='Validation Loss')\n",
    "plt.legend(loc ='upper right')\n",
    "plt.title('Training and Validation Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e1306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the results \n",
    "predict = model.predict(testX,batch_size = BATCH_SIZE)\n",
    "predict = np.argmax(predict,axis=1)\n",
    "print(classification_report(testY.argmax(axis=1),predict,target_names= lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ee1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To save the model \n",
    "model.save('mobilenetv2_face_mask_detector_dataset3.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
